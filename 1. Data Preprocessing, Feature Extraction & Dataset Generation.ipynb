{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_df = pd.read_csv('data/files/5_keystrokes.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "$PT_t$ -> Press Time at timestep t\\\n",
    "$RT_t$ -> Release Time at timestamp t\n",
    "\n",
    "* In paper they used four latency features:\n",
    "* * Hold Latency                      \n",
    "* * Inter-key Latency\n",
    "* * Press Latency\n",
    "* * Release Latency\n",
    "\n",
    "$$\n",
    "HL = RT_t - PT_t \\\\\n",
    "IL = PT_t - RT_{t-1} \\\\\n",
    "PL = PT_t - PT_{t-1} \\\\\n",
    "RL = RT_t - RT_{t-1}\n",
    "$$\n",
    "\n",
    "So for a sequence with timestamp T we will collect t-1 latency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "section_ids = keys_df['TEST_SECTION_ID'].unique().tolist()\n",
    "keys_df_example = keys_df[keys_df['TEST_SECTION_ID'] == section_ids[0]]\n",
    "\n",
    "keys_df_example['PRESS_TIME_lag'] = keys_df_example['PRESS_TIME'].shift(1)\n",
    "keys_df_example['PRESS_TIME_lag'] = np.where(keys_df_example['PRESS_TIME_lag'].isna(), keys_df_example['PRESS_TIME'], keys_df_example['PRESS_TIME_lag'])\n",
    "\n",
    "keys_df_example['RELEASE_TIME_lag'] = keys_df_example['RELEASE_TIME'].shift(1)\n",
    "keys_df_example['RELEASE_TIME_lag'] = np.where(keys_df_example['RELEASE_TIME_lag'].isna(), keys_df_example['RELEASE_TIME'], keys_df_example['RELEASE_TIME_lag'])\n",
    "\n",
    "keys_df_example['PRESS_TIME_lag'] = keys_df_example['PRESS_TIME_lag'].astype('int64')\n",
    "keys_df_example['RELEASE_TIME_lag'] = keys_df_example['RELEASE_TIME_lag'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_df_example['HL'] =  keys_df_example['RELEASE_TIME'] - keys_df_example['PRESS_TIME']\n",
    "keys_df_example['IL'] = keys_df_example['PRESS_TIME'] - keys_df_example['RELEASE_TIME_lag']\n",
    "keys_df_example['PL'] = keys_df_example['PRESS_TIME'] - keys_df_example['PRESS_TIME_lag']\n",
    "keys_df_example['RL'] = keys_df_example['RELEASE_TIME'] - keys_df_example['RELEASE_TIME_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_df_example.TEST_SECTION_ID.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_utils import extract_latency_features_from_df as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = keys_df[keys_df['TEST_SECTION_ID'] == section_ids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = p(test_case,\n",
    " 'PRESS_TIME',\n",
    " 'RELEASE_TIME',\n",
    " 'KEYCODE',\n",
    " 'PARTICIPANT_ID',\n",
    " 'TEST_SECTION_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 47, 47, 47, 47)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(output['keycode_ids']),\n",
    "len(output['hl']),\n",
    "len(output['il']),\n",
    "len(output['pl']),\n",
    "len(output['rl']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from entire dataset & saving in one format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('data/metadata_participants.txt', sep='\\t')\n",
    "meta_df = meta_df[meta_df['LAYOUT'] =='qwerty']\n",
    "meta_df = meta_df[meta_df['KEYBOARD_TYPE'].isin(['full', 'laptop'])]\n",
    "\n",
    "\n",
    "ids_of_interest = meta_df['PARTICIPANT_ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all of the files, that are were typed in qwerty and on laptop/pc\n",
    "keystrokes_data_files = [f'{i}_keystrokes.txt' for i in ids_of_interest]\n",
    "keystrokes_real_files = os.listdir('data/files/')\n",
    "\n",
    "keystrokes_data_files = sorted(list(set(keystrokes_data_files).intersection(set(keystrokes_real_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162056/162056 [13:37<00:00, 198.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6048"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataframes = []\n",
    "failed_files = []\n",
    "for path in tqdm(keystrokes_data_files):\n",
    "    data_path = os.path.join(os.getcwd(), fr'data/files/{path}')\n",
    "    try:\n",
    "        df = pd.read_csv(data_path, sep='\\t')\n",
    "        for id in sorted(df.TEST_SECTION_ID.unique()):\n",
    "            curr_df = df[df.TEST_SECTION_ID == id]\n",
    "            dataframes.append(curr_df)\n",
    "    except:\n",
    "        failed_files.append(data_path)\n",
    "\n",
    "\n",
    "len(failed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.DataFrame()\n",
    "final_dataset['frames'] = dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 24 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    try:\n",
    "        sample = final_dataset.sample(5000, random_state=i)\n",
    "        sample.apply(lambda x: p(x.frames,\n",
    "                             'PRESS_TIME',\n",
    "                             'RELEASE_TIME',\n",
    "                               'KEYCODE',\n",
    "                               'PARTICIPANT_ID',\n",
    "                               'TEST_SECTION_ID'),\n",
    "                                axis='columns',\n",
    "                                result_type='expand')\n",
    "    except Exception as e:\n",
    "        print(i, '\\n', e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "for idx, frame in enumerate(sample.frames):\n",
    "    try:\n",
    "        p(frame,\n",
    "          'PRESS_TIME',\n",
    "          'RELEASE_TIME',\n",
    "          'KEYCODE',\n",
    "          'PARTICIPANT_ID',\n",
    "          'TEST_SECTION_ID')\n",
    "    except:\n",
    "        print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandarallel/core.py\", line 95, in __call__\n    result = self.work_function(\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandarallel/data_types/dataframe.py\", line 32, in work\n    return data.apply(\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/frame.py\", line 9423, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/apply.py\", line 678, in apply\n    return self.apply_standard()\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/apply.py\", line 798, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/apply.py\", line 814, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/tmp/ipykernel_763189/3356422957.py\", line 1, in <lambda>\n    final_dataset = final_dataset.parallel_apply(lambda x: p(x.frames,\n  File \"/home/TZholaman/keystrokes/GoNet/preprocessing_utils.py\", line 41, in extract_latency_features_from_df\n    dataframe[f'{col}_lag'] = dataframe[f'{col}_lag'].astype('int64')\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/generic.py\", line 6324, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 451, in astype\n    return self.apply(\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 352, in apply\n    applied = getattr(b, f)(**kwargs)\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 511, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/dtypes/astype.py\", line 242, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/dtypes/astype.py\", line 187, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/dtypes/astype.py\", line 105, in _astype_nansafe\n    return _astype_float_to_int_nansafe(arr, dtype, copy)\n  File \"/home/TZholaman/temirlan_dev/lib/python3.8/site-packages/pandas/core/dtypes/astype.py\", line 150, in _astype_float_to_int_nansafe\n    raise IntCastingNaNError(\npandas.errors.IntCastingNaNError: Cannot convert non-finite values (NA or inf) to integer\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPRESS_TIME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRELEASE_TIME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKEYCODE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPARTICIPANT_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEST_SECTION_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/temirlan_dev/lib/python3.8/site-packages/pandarallel/core.py:333\u001b[0m, in \u001b[0;36mparallelize_with_memory_file_system.<locals>.closure\u001b[0;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_reduce_function(\n\u001b[1;32m    326\u001b[0m         (Path(output_file\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mfor\u001b[39;00m output_file \u001b[38;5;129;01min\u001b[39;00m output_files),\n\u001b[1;32m    327\u001b[0m         reduce_extra,\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# Loading the files failed, this most likely means that there\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# was some error during processing and the files were never\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# saved at all.\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[43mresults_promise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# If the above statement does not raise an exception, that\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# means the multiprocessing went well and we want to re-raise\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# the original EOFError.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "final_dataset = final_dataset.parallel_apply(lambda x: p(x.frames,\n",
    "                                                        'PRESS_TIME',\n",
    "                                                        'RELEASE_TIME',\n",
    "                                                        'KEYCODE',\n",
    "                                                        'PARTICIPANT_ID',\n",
    "                                                        'TEST_SECTION_ID'),\n",
    "                                            axis='columns',\n",
    "                                            result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626795675568939"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.8% of data is corrupted\n",
    "(len(keystrokes_data_files) - len(failed_files))/len(keystrokes_data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dataset in huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_136Mkeystrokes_features = Dataset.from_pandas(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['participant_id', 'section_id', 'keycode_ids', 'hl', 'il', 'pl', 'rl'],\n",
       "    num_rows: 1455\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_136Mkeystrokes_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temirlan_dev",
   "language": "python",
   "name": "temirlan_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
